I"Æz<h2 id="1-ë”¥ëŸ¬ë‹-í”„ë ˆì„-ì›Œí¬">1. ë”¥ëŸ¬ë‹ í”„ë ˆì„ ì›Œí¬</h2>

<p>ë”¥ëŸ¬ë‹ì´ë¼ëŠ” ê¸°ìˆ ì„ ë‹¨ìˆœíˆ ìì²´ ì½”ë“œë¡œ êµ¬í˜„ì„ í•˜ë ¤ë©´ ìƒê°ë³´ë‹¤ ì˜¤ëœì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤. íŠ¹íˆ, ëª¨ë¸ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ êµ¬í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ êµ¬í˜„í•˜ë ¤ë©´ ë¨¸ë¦¬ê°€ ì•„í”•ë‹ˆë‹¤.</p>

<p>í•˜ì§€ë§Œ íŒŒì´ì¬ì—ëŠ” ë”¥ëŸ¬ë‹ ê¸°ìˆ ì„ êµ¬í˜„ì‹œí‚¤ëŠ”ë° ë„ì›€ì„ ì£¼ëŠ” ë‹¤ìˆ˜ì˜ í”„ë ˆì„ ì›Œí¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.</p>

<p><a href="https://em360tech.com/top-10/machine-learning-is-deep">2021ë…„ ìµœê³ ì˜ ë”¥ëŸ¬ë‹ í”„ë ˆì„ ì›Œí¬ Top10</a></p>
<ol>
  <li>Tensorflow</li>
  <li>PyTorch</li>
  <li>Keras</li>
  <li>Sonnet</li>
  <li>Caffe</li>
  <li>Microsoft Cognitive Toolkit</li>
  <li>MXNet</li>
  <li>Gluon</li>
  <li>DL4J</li>
  <li>ONNX</li>
</ol>

<p>ì €í¬ë“¤ì€ ì´ ì¤‘ì—ì„œ ê°€ì¥ ì¸ê¸°ê°€ í”„ë ˆì„ ì›Œí¬ì¸ Tensorflowë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h2 id="2-tensorflow">2. Tensorflow</h2>

<p>Tensorflowë¥¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ë©´ êµ¬ê¸€ì—ì„œ ë°°í¬í•œ ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼ìœ¼ë¡œ ëª¨ë“  ì¢…ë¥˜ì˜ AIê°œë°œì„ ì§€ì›í•´ì¤ë‹ˆë‹¤.</p>

<h3 id="21-tensorflow-v1">2.1 Tensorflow V1</h3>

<p>TensorflowëŠ” ëª¨ë¸ì˜ ìˆœì „íŒŒë¶€ë¶„ë§Œ ì„¤ê³„ë¥¼ í•˜ë©´ ê·¸ ëª¨ë¸ì˜ ê·¸ë˜ë””ì–¸íŠ¸(ë¯¸ë¶„ê°’)ì„ ì‚¬ì „ì— êµ¬í•´ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ëŸ¬í•œ íŠ¹ì§•ì€ Tensorflow V1ë•Œë¶€í„° ë‚´ë ¤ì˜¨ <code class="language-plaintext highlighter-rouge">Directed Acyclic Graph(DAG : ìœ í–¥ ë¹„ìˆœí™˜ ê·¸ë˜í”„)</code> ë•ë¶„ì…ë‹ˆë‹¤.
DAG ë•ë¶„ì— ë…¸ë“œì™€ ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ë§¤ ì—£ì§€ë§ˆë‹¤ chain-ruleì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì—­ë°©í–¥ìœ¼ë¡œ ì „íŒŒë  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.
ì´ëŸ¬í•œ ë°©ì‹ì„ Tensorflowì˜ <code class="language-plaintext highlighter-rouge">Graph Mode</code> ë¼ê³  í•©ë‹ˆë‹¤.</p>

<p>í•˜ì§€ë§Œ ì´ëŸ¬í•œ ì„¤ê³„ ë•Œë¬¸ì— Tensorflow V1ì€</p>
<ul>
  <li>ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ê³¼ì •</li>
  <li>ê·¸ë˜í”„ ìƒì—ì„œ ì—°ì‚°ì´ ì‹¤ì œ ì§„í–‰ë˜ëŠ” ê³¼ì •
2ê°€ì§€ ê³¼ì •ì„ <code class="language-plaintext highlighter-rouge">session</code>ì„ í†µí•˜ì—¬ ì—„ê²©í•˜ê²Œ ë¶„ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ê·¸ë˜í”„ ì‚¬ì´ì—ì„œ ë²Œì–´ì§€ëŠ” ëª¨ë“  ì—°ì‚°ì€ ë°˜ë“œì‹œ <code class="language-plaintext highlighter-rouge">session.run()</code>ì•ˆì—ì„œ ìˆ˜í–‰ë˜ë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.</li>
</ul>

<p>ì´ëŸ¬í•œ ë°©ì‹ì´ ì£¼ëŠ” ì´ì ì€</p>
<ul>
  <li>ëŒ€ê·œëª¨ ë¶„ì‚° í™˜ê²½ì—ì„œì˜ í™•ì¥ì„±</li>
  <li>ëŒ€ê·œëª¨ ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ìƒì‚°ì„±</li>
</ul>

<p>ë‹¨ì ìœ¼ë¡œëŠ”</p>
<ul>
  <li>ì½”ë“œê°€ ê¸¸ê³  íŒŒì´ì¨ë‹‰í•˜ì§€ ëª»í•¨</li>
  <li>êµ¬í˜„ ë°©ì‹ì´ ìƒë‹¹íˆ ì–´ë ¤ì›€</li>
  <li>ê·¸ë˜í”„ë¥¼ ë§Œë“¤ê³  ëŒë ¤ë´ì•¼ ë¹„ë¡œì†Œ ëª¨ë¸ êµ¬ì„± ë¬¸ì œê°€ ë“œëŸ¬ë‚¨</li>
</ul>

<h3 id="22-tensorflow-v2">2.2 Tensorflow V2</h3>

<p>í•˜ì§€ë§Œ Tensorflowê°€ V2ë¡œ ì—…ê·¸ë ˆì´ë“œë˜ë©´ì„œ ë§ì€ ë³€í™”ê°€ ìƒê²¨ë‚¬ìŠµë‹ˆë‹¤.
ë‹¤ì–‘í•œ ë³€í™”ë“¤ì¤‘ì—ì„œ ëŒ€í‘œì ì¸ ê²ƒìœ¼ë¡œ</p>
<ul>
  <li>PyTorchì˜ <code class="language-plaintext highlighter-rouge">Eager Mode</code>ë¥¼ ìˆ˜ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
    <ul>
      <li>Eager ModeëŠ” ë”¥ëŸ¬ë‹ ê·¸ë˜í”„ê°€ ë‹¤ ê·¸ë ¤ì§€ì§€ ì•Šì•„ë„ ì–¼ë§ˆë“ ì§€ ë¶€ë¶„ì‹¤í–‰ ë° ì˜¤ë¥˜ê²€ì¦ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</li>
      <li>ì½”ë“œë„ ê°„ê²°í•˜ê³  íŒŒì´ì¨ë‹‰í•œ ì„¤ê³„ë¥¼ ê°€ì¡ŒìŠµë‹ˆë‹¤.</li>
    </ul>
  </li>
  <li>Kerasì˜ ì‰½ê³  ê°„ê²°í•œ ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ ì›Œí¬ë¥¼ ìˆ˜ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.</li>
</ul>

<p>ì´ëŸ¬í•œ ë³€í™”ë“¤ì´ ìˆì—ˆìœ¼ë©° ì¶”ê°€ì ì¸ ë³€í™” ë‚´ìš©ì€ ë‹¤ìŒ <a href="https://www.datasciencecentral.com/profiles/blogs/tensorflow-1-x-vs-2-x-summary-of-changes">ë§í¬</a>ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># í…ì„œí”Œë¡œ 1.x
</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">placeholder</span><span class="p">),</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">placeholder</span><span class="p">:</span> <span class="nb">input</span><span class="p">})</span>
<span class="c1"># í…ì„œí”Œë¡œ 2.0
</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></div></div>

<p>ìœ„ì˜ ë‘ ì½”ë“œëŠ” ì„œë¡œ ê°™ì€ ê¸°ëŠ¥ì„ í•˜ì§€ë§Œ ë²„ì „ì— ë”°ë¥¸ ì°¨ì´ë¡œ Tensorflow V1ê³¼ V2ì˜ êµ¬í˜„ ë°©ì‹ì´ í¬ê²Œ ê°„ì†Œí™”ëœ ê²ƒì„ ì•Œ ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.</p>

<p>ì§ê´€ì ì¸ ì½”ë“œì˜ ê¸¸ì´ ë§ê³ ë„, TensorflowëŠ” Session.run()ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , ê·¸ë˜í”„ë¥¼ ì™„ì„±í•˜ì§€ ì•Šì•„ë„ ë¶€ë¶„ ì‹¤í–‰ì´ ê°€ëŠ¥í•œ Eager Modeì˜ ì¥ì ë“¤ì¸ ì„¤ê³„, êµ¬í˜„, ë””ë²„ê¹… ì „ê³¼ì •ì„ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ë°”ë€ ê²ƒì„ ì•Œ ìˆ˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<h2 id="3-tf2-api">3. TF2 API</h2>

<p>ë”¥ëŸ¬ë‹ ê¸°ìˆ ì„ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ Tensorflow ì—ì„œëŠ” 3ê°€ì§€ ìœ í˜•ì˜ APIë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>
<ul>
  <li>Sequential Model</li>
  <li>Functional Model</li>
  <li>Subclassing Model</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
</span><span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>
</code></pre></div></div>

<p>ì§€ê¸ˆë¶€í„°ëŠ” Tensorflowì—ì„œ ì œê³µí•˜ëŠ” MNIST ë°ì´í„°ì…‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ì„ ë™ì¼í•œ êµ¬ì¡°ë¡œ APIë§Œ ë‹¤ë¥´ê²Œ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h3 id="31-sequential-model">3.1 Sequential Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sequential Model ì„¤ê³„
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># ëª¨ë¸ ì„¤ì • ì»´íŒŒì¼
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ loss     : </span><span class="si">{</span><span class="n">test_loss</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ accuracy : </span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1875/1875 [==============================] - 4s 2ms/step - loss: 0.4746 - accuracy: 0.8621
313/313 - 1s - loss: 0.1473 - accuracy: 0.9566
ëª¨ë¸ì˜ loss     : 0.14732250571250916
ëª¨ë¸ì˜ accuracy : 0.95660001039505
</code></pre></div></div>

<h3 id="32-functional-api">3.2 Functional API</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Functional ëª¨ë¸ ì„¤ê³„
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">)</span>

<span class="c1"># ëª¨ë¸ ì„¤ì • ì»´íŒŒì¼
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ loss     : </span><span class="si">{</span><span class="n">test_loss</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ accuracy : </span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1875/1875 [==============================] - 4s 2ms/step - loss: 0.4915 - accuracy: 0.8543
313/313 - 1s - loss: 0.1515 - accuracy: 0.9537
ëª¨ë¸ì˜ loss     : 0.151547372341156
ëª¨ë¸ì˜ accuracy : 0.9537000060081482
</code></pre></div></div>

<h3 id="33-subclassing-api">3.3 Subclassing API</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Subclassing ëª¨ë¸ ì„¤ê³„
</span><span class="k">class</span> <span class="nc">Subclass_model</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Subclass_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"relu"</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"softmax"</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">Subclass_model</span><span class="p">()</span>

<span class="c1"># ëª¨ë¸ ì„¤ì • ì»´íŒŒì¼
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ loss     : </span><span class="si">{</span><span class="n">test_loss</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ëª¨ë¸ì˜ accuracy : </span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1875/1875 [==============================] - 4s 2ms/step - loss: 0.4815 - accuracy: 0.8585
313/313 - 1s - loss: 0.1446 - accuracy: 0.9569
ëª¨ë¸ì˜ loss     : 0.1445624679327011
ëª¨ë¸ì˜ accuracy : 0.9569000005722046
</code></pre></div></div>

<h2 id="4-compile-fit-ëœ¯ì–´ë³´ê¸°">4. compile, fit ëœ¯ì–´ë³´ê¸°</h2>

<p>ëª¨ë¸ì˜ lossì™€ optimizerë¥¼ ì§€ì •í•˜ê³  ëª¨ë¸ì˜ ê²½ê³¼ë¥¼ ì§€ì¼œë³¼ ìˆ˜ ìˆëŠ” metricsë¥¼ ì§€ì •í•´ì£¼ëŠ” <code class="language-plaintext highlighter-rouge">model.compile()</code> í•¨ìˆ˜ì™€ ì…ë ¥ ë°ì´í„°ë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ì„œ ëª¨ë¸ì— ë„£ì–´ì£¼ê³  ì „ì²´ ëª¨ë¸ì˜ í•™ìŠµ ì •ë„ë¥¼ ì¡°ì ˆí•´ì£¼ëŠ” <code class="language-plaintext highlighter-rouge">model.fit()</code> í•¨ìˆ˜ë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.</p>

<h3 id="41-modelcompile">4.1 model.compile</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<p>ì•ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•œ ëª¨ë¸ì˜ í•™ìŠµ ë°©ì‹ì„ ì„¤ì •í•˜ëŠ” <code class="language-plaintext highlighter-rouge">model.compile()</code>í•¨ìˆ˜ëŠ” ë§¤ ìŠ¤í… í•™ìŠµì´ ì§„í–‰ë  ë•Œ ì§€ì •ëœ optimizerë¡œ ì§€ì •ëœ lossë¥¼ ì¤„ì´ëŠ” ê³¼ì •ì´ ìë™ìœ¼ë¡œ ì§„í–‰ë˜ì–´ì§€ëŠ”ë° ì´ ê³¼ì •ì„ ì»¤ìŠ¤í…€ë§ˆì´ì§•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># loss functionë¥¼ SparseCategoricalCrossentropy ë¡œ ë¯¸ë¦¬ ì§€ì •
</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
<span class="c1"># optimizerë¥¼ Adam ìœ¼ë¡œ ë¯¸ë¦¬ ì§€ì •
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">()</span>

<span class="c1"># tf.GradientTape()ë¥¼ í™œìš©í•œ train_step
</span><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="c1"># 1. ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë¡ ì‹œì‘
</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="c1"># 2. modelì˜ ì˜ˆì¸¡ê°’
</span>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="c1"># 3. ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="c1"># 4. í•™ìŠµê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë³„ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì¶œ
</span>        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="c1"># 5. ì¶”ì¶œëœ ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">model.trainable_variables</code>ëŠ” ì—…ë°ì´íŠ¸ í•´ì•¼í•˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ì„ ì§€ì •í•´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.</p>

<h3 id="42-modelfit">4.2 model.fit</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>ì‹¤ì œ í•™ìŠµì´ ì§„í–‰ë˜ëŠ” í•¨ìˆ˜ì¸ <code class="language-plaintext highlighter-rouge">model.fit()</code>ëŠ” ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ë°°ì¹˜ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì•ì—ì„œ ë§Œë“  í•™ìŠµ í•¨ìˆ˜ì¸<code class="language-plaintext highlighter-rouge">train_step</code>ì— ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥í•˜ê³ , ì…ë ¥í•˜ì—¬ ë‚˜ì˜¨ loss ì™€ accuracy ë¥¼ ë°˜í™˜í•˜ëŠ” ë°˜ë³µë¬¸ì´ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="c1"># ì‹œì‘ ì‹œê°„
</span>    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># ëª¨ë¸ epoch
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># ëª¨ë¸ step
</span>        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))):</span>
            <span class="c1"># ì˜ˆì œì´ë¯€ë¡œ batch_sizeë²ˆì§¸ ë°ì´í„°ë§Œ í•™ìŠµì‹œí‚´
</span>            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="n">batch_size</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">x_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">y_batch</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
                <span class="n">x_batch</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Epoch %d: last batch loss = %.4f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"It took {} seconds"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

<span class="n">train_model</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>60000it [00:14, 4069.26it/s]

Epoch 0: last batch loss = 0.0009
It took 14.747461080551147 seconds
</code></pre></div></div>

<p>â€‹</p>

:ET